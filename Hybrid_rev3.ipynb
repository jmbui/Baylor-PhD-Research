{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Hybrid_rev3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPij96SCJ/alxgLw4CMYTUS"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pzBB4pZJuv3"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "%load_ext tensorboard \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, datasets, utils, backend, Model\n",
        "import datetime\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import time\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "!rm -rf ./logs/\n",
        "\n",
        "#tf.config.run_functions_eagerly(True)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGaulBPRJw-Z",
        "outputId": "e1c33746-06c7-452c-d9c0-8576c2c5c6be"
      },
      "source": [
        "def img_rmse(image1, image2):\n",
        "  error = np.sqrt(np.sum((image1.astype('float')-image2.astype('float'))**2))\n",
        "  return error\n",
        "\n",
        "# Load MNIST and Fashion datasets\n",
        "mn = tf.keras.datasets.mnist\n",
        "fs = tf.keras.datasets.fashion_mnist\n",
        "(mx_train, my_train), (mx_test, my_test) = mn.load_data() # MNIST\n",
        "(fx_train, fy_train), (fx_test, fy_test) = fs.load_data() # Fashion MNIST\n",
        "\n",
        "# Normalize Image values to [0,1]\n",
        "mx_train = mx_train/255.0\n",
        "mx_test = mx_test/255.0\n",
        "fx_train = fx_train/255.0\n",
        "fx_test = fx_test/255.0\n",
        "# One Hot Encode the categories, num_classes = 10\n",
        "my_train = utils.to_categorical(my_train)\n",
        "my_test = utils.to_categorical(my_test)\n",
        "fy_train = utils.to_categorical(fy_train)\n",
        "fy_test = utils.to_categorical(fy_test)\n",
        "# Get Image Dimensions, store into img_size\n",
        "\n",
        "img_w = mx_train.shape[1]\n",
        "img_h = mx_train.shape[2]\n",
        "\n",
        "# Get Image shape and number of labels in the classifier\n",
        "img_shape = (img_w, img_h, 1)\n",
        "num_labels = my_train.shape[1]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgDuX4M4Kb7a"
      },
      "source": [
        "# Hyperparameters for Hybrid and Independent neural networks\n",
        "input_shape = img_shape\n",
        "batch_size = 64\n",
        "kernel_size = (3,3)\n",
        "pool_size = (2,2)\n",
        "latent_dim = 64\n",
        "filters = 64\n",
        "layer_filters = [32, 64]\n",
        "dropout = .25\n",
        "Epochs = 20"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i-L5f4nLm7_"
      },
      "source": [
        "# Build the Hybrid Network\n",
        "\n",
        "# Core Network Layers\n",
        "inputs = tf.keras.layers.Input(shape = input_shape, name = 'common_input')\n",
        "x = inputs\n",
        "\n",
        "for filters in layer_filters:\n",
        "  x = tf.keras.layers.Conv2D(filters = filters, kernel_size= kernel_size,\n",
        "                             activation = 'relu', padding = 'same')(x)\n",
        "shape = tf.keras.backend.int_shape(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "core = tf.keras.layers.Dense(latent_dim, name = 'waist') (x)\n",
        "\n",
        "# Classifier Network Sublayers\n",
        "flat = (tf.keras.layers.Flatten())(core)\n",
        "drop = (tf.keras.layers.Dropout(dropout))(flat)\n",
        "\n",
        "dense = (tf.keras.layers.Dense(num_labels))(drop)\n",
        "class_out = (tf.keras.layers.Activation('softmax', name = \"Classifier\"))(dense)\n",
        "\n",
        "# Autoencoder Network Sublayers\n",
        "x = tf.keras.layers.Dense(shape[1] * shape[2] * shape[3])(core)\n",
        "x = tf.keras.layers.Reshape((shape[1], shape[2], shape[3]))(x)\n",
        "\n",
        "for filters in layer_filters[::-1]:\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters = filters, \n",
        "                                      kernel_size = kernel_size,\n",
        "                                      activation = 'relu', strides = 2, \n",
        "                                      padding = 'same')(x)\n",
        "\n",
        "auto_out = tf.keras.layers.Conv2DTranspose(filters = 1, \n",
        "                                      kernel_size = kernel_size,\n",
        "                                      activation = 'sigmoid', padding = 'same',\n",
        "                                      name = 'Generator')(x)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiA94EEGRNeL"
      },
      "source": [
        "# Build the Hybrid Network\n",
        "\n",
        "# Core Network Layers\n",
        "inputs2 = tf.keras.layers.Input(shape = input_shape, name = 'common_input')\n",
        "x = inputs2\n",
        "\n",
        "for filters in layer_filters:\n",
        "  x = tf.keras.layers.Conv2D(filters = filters, kernel_size= kernel_size,\n",
        "                             activation = 'relu', strides = 2, \n",
        "                             padding = 'same')(x)\n",
        "shape = tf.keras.backend.int_shape(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "core = tf.keras.layers.Dense(latent_dim, name = 'waist') (x)\n",
        "\n",
        "# Classifier Network Sublayers\n",
        "flat = (tf.keras.layers.Flatten())(core)\n",
        "drop = (tf.keras.layers.Dropout(dropout))(flat)\n",
        "\n",
        "dense = (tf.keras.layers.Dense(num_labels))(drop)\n",
        "class_out2 = (tf.keras.layers.Activation('softmax', name = \"Classifier2\"))(dense)\n",
        "\n",
        "# Autoencoder Network Sublayers\n",
        "x = tf.keras.layers.Dense(shape[1] * shape[2] * shape[3])(core)\n",
        "x = tf.keras.layers.Reshape((shape[1], shape[2], shape[3]))(x)\n",
        "\n",
        "for filters in layer_filters[::-1]:\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters = filters, \n",
        "                                      kernel_size = kernel_size,\n",
        "                                      activation = 'relu', strides = 2, \n",
        "                                      padding = 'same')(x)\n",
        "\n",
        "auto_out2 = tf.keras.layers.Conv2DTranspose(filters = 1, \n",
        "                                      kernel_size = kernel_size,\n",
        "                                      activation = 'sigmoid', padding = 'same',\n",
        "                                      name = 'Generator2')(x)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2p8YJlERiR7"
      },
      "source": [
        "# Build the Hybrid Network\n",
        "\n",
        "# Core Network Layers\n",
        "inputs3 = tf.keras.layers.Input(shape = input_shape, name = 'common_input')\n",
        "x = inputs3\n",
        "\n",
        "for filters in layer_filters:\n",
        "  x = tf.keras.layers.Conv2D(filters = filters, kernel_size= kernel_size,\n",
        "                             activation = 'relu', strides = 2, \n",
        "                             padding = 'same')(x)\n",
        "shape = tf.keras.backend.int_shape(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "core = tf.keras.layers.Dense(latent_dim, name = 'waist') (x)\n",
        "\n",
        "# Classifier Network Sublayers\n",
        "flat = (tf.keras.layers.Flatten())(core)\n",
        "drop = (tf.keras.layers.Dropout(dropout))(flat)\n",
        "\n",
        "dense = (tf.keras.layers.Dense(num_labels))(drop)\n",
        "class_out3 = (tf.keras.layers.Activation('softmax', name = \"Classifier3\"))(dense)\n",
        "\n",
        "# Autoencoder Network Sublayers\n",
        "x = tf.keras.layers.Dense(shape[1] * shape[2] * shape[3])(core)\n",
        "x = tf.keras.layers.Reshape((shape[1], shape[2], shape[3]))(x)\n",
        "\n",
        "for filters in layer_filters[::-1]:\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters = filters, \n",
        "                                      kernel_size = kernel_size,\n",
        "                                      activation = 'relu', strides = 2, \n",
        "                                      padding = 'same')(x)\n",
        "\n",
        "auto_out3 = tf.keras.layers.Conv2DTranspose(filters = 1, \n",
        "                                      kernel_size = kernel_size,\n",
        "                                      activation = 'sigmoid', padding = 'same',\n",
        "                                      name = 'Generator3')(x)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERS1Uab8SCbP"
      },
      "source": [
        "# Build the Hybrid Network\n",
        "\n",
        "# Core Network Layers\n",
        "inputs4 = tf.keras.layers.Input(shape = input_shape, name = 'common_input')\n",
        "x = inputs4\n",
        "\n",
        "for filters in layer_filters:\n",
        "  x = tf.keras.layers.Conv2D(filters = filters, kernel_size= kernel_size,\n",
        "                             activation = 'relu', strides = 2, \n",
        "                             padding = 'same')(x)\n",
        "shape = tf.keras.backend.int_shape(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "core = tf.keras.layers.Dense(latent_dim, name = 'waist') (x)\n",
        "\n",
        "# Classifier Network Sublayers\n",
        "flat = (tf.keras.layers.Flatten())(core)\n",
        "drop = (tf.keras.layers.Dropout(dropout))(flat)\n",
        "\n",
        "dense = (tf.keras.layers.Dense(num_labels))(drop)\n",
        "class_out4 = (tf.keras.layers.Activation('softmax', name = \"Classifier4\"))(dense)\n",
        "\n",
        "# Autoencoder Network Sublayers\n",
        "x = tf.keras.layers.Dense(shape[1] * shape[2] * shape[3])(core)\n",
        "x = tf.keras.layers.Reshape((shape[1], shape[2], shape[3]))(x)\n",
        "\n",
        "for filters in layer_filters[::-1]:\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters = filters, \n",
        "                                      kernel_size = kernel_size,\n",
        "                                      activation = 'relu', strides = 2, \n",
        "                                      padding = 'same')(x)\n",
        "\n",
        "auto_out4 = tf.keras.layers.Conv2DTranspose(filters = 1, \n",
        "                                      kernel_size = kernel_size,\n",
        "                                      activation = 'sigmoid', padding = 'same',\n",
        "                                      name = 'Generator4')(x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wxu0uMPSHjA"
      },
      "source": [
        "# Build the Hybrid Network\n",
        "\n",
        "# Core Network Layers\n",
        "inputs5 = tf.keras.layers.Input(shape = input_shape, name = 'common_input')\n",
        "x = inputs5\n",
        "\n",
        "for filters in layer_filters:\n",
        "  x = tf.keras.layers.Conv2D(filters = filters, kernel_size= kernel_size,\n",
        "                             activation = 'relu', strides = 2, \n",
        "                             padding = 'same')(x)\n",
        "shape = tf.keras.backend.int_shape(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "core = tf.keras.layers.Dense(latent_dim, name = 'waist') (x)\n",
        "\n",
        "# Classifier Network Sublayers\n",
        "flat = (tf.keras.layers.Flatten())(core)\n",
        "drop = (tf.keras.layers.Dropout(dropout))(flat)\n",
        "\n",
        "dense = (tf.keras.layers.Dense(num_labels))(drop)\n",
        "class_out5 = (tf.keras.layers.Activation('softmax', name = \"Classifier5\"))(dense)\n",
        "\n",
        "# Autoencoder Network Sublayers\n",
        "x = tf.keras.layers.Dense(shape[1] * shape[2] * shape[3])(core)\n",
        "x = tf.keras.layers.Reshape((shape[1], shape[2], shape[3]))(x)\n",
        "\n",
        "for filters in layer_filters[::-1]:\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters = filters, \n",
        "                                      kernel_size = kernel_size,\n",
        "                                      activation = 'relu', strides = 2, \n",
        "                                      padding = 'same')(x)\n",
        "\n",
        "auto_out5 = tf.keras.layers.Conv2DTranspose(filters = 1, \n",
        "                                      kernel_size = kernel_size,\n",
        "                                      activation = 'sigmoid', padding = 'same',\n",
        "                                      name = 'Generator5')(x)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf9bnfRbLnPh"
      },
      "source": [
        "\n",
        "#  CL Hybrid, fully weighed to generator, should match Classifier\n",
        "cl_Hyb = tf.keras.Model(inputs = inputs2,\n",
        "                          outputs = [class_out2, auto_out2],)\n",
        "\n",
        "cl_Hyb.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=.001),\n",
        "    loss={\n",
        "        \"Classifier2\": tf.keras.losses.categorical_crossentropy,\n",
        "        \"Generator2\": tf.keras.losses.MSE,\n",
        "    },\n",
        "    loss_weights=[1,0],\n",
        "       metrics = ['accuracy']    \n",
        ")\n",
        "\n",
        "#  25% Classifier, 75% Generator\n",
        "a_Hyb = tf.keras.Model(inputs = inputs3,\n",
        "                          outputs = [class_out3, auto_out3],)\n",
        "\n",
        "a_Hyb.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=.001),\n",
        "    loss={\n",
        "        \"Classifier3\": tf.keras.losses.categorical_crossentropy,\n",
        "        \"Generator3\": tf.keras.losses.MSE,\n",
        "    },\n",
        "    loss_weights=[.25, .75],\n",
        "       metrics = ['accuracy']    \n",
        ")\n",
        "\n",
        "#  50% Classifier, 50% Generator\n",
        "b_Hyb = tf.keras.Model(inputs = inputs4,\n",
        "                          outputs = [class_out4, auto_out4],)\n",
        "\n",
        "b_Hyb.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=.001),\n",
        "    loss={\n",
        "        \"Classifier4\": tf.keras.losses.categorical_crossentropy,\n",
        "        \"Generator4\": tf.keras.losses.MSE,\n",
        "    },\n",
        "    loss_weights=[.5, .5],\n",
        "       metrics = ['accuracy']    \n",
        ")\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tb_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqEBq_ovXZjv"
      },
      "source": [
        "# Build the independent classifier and autoencoder\n",
        "\n",
        "# Build the Convolutional Neural Network\n",
        "\n",
        "cnn = tf.keras.models.Sequential()\n",
        "# First Layers\n",
        "cnn.add(tf.keras.layers.Conv2D(filters = filters, kernel_size=kernel_size,\n",
        "                               activation = 'relu', input_shape = input_shape))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(pool_size))\n",
        "# Second Layers\n",
        "cnn.add(tf.keras.layers.Conv2D(filters = filters, kernel_size = kernel_size,\n",
        "                               activation = 'relu'))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(pool_size))\n",
        "# 3rd Layers\n",
        "cnn.add(tf.keras.layers.Conv2D(filters = filters, kernel_size = kernel_size,\n",
        "                               activation = 'relu'))\n",
        "cnn.add(tf.keras.layers.MaxPooling2D(pool_size))\n",
        "\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dropout(dropout))\n",
        "\n",
        "cnn.add(tf.keras.layers.Dense(num_labels))\n",
        "cnn.add(tf.keras.layers.Activation('softmax'))\n",
        "#cnn.summary()\n",
        "tf.keras.utils.plot_model (cnn, to_file = 'cnn_structure.png', \n",
        "                           show_shapes = True)\n",
        "cnn.compile(loss = 'categorical_crossentropy', optimizer = 'adam',\n",
        "            metrics = ['accuracy'])\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# The Autoencoder Model\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape = input_shape, name = 'encoder_input')\n",
        "x = inputs\n",
        "\n",
        "for filters in layer_filters:\n",
        "  x = tf.keras.layers.Conv2D(filters = filters, kernel_size= kernel_size,\n",
        "                             activation = 'relu', strides = 2, \n",
        "                             padding = 'same')(x)\n",
        "shape = tf.keras.backend.int_shape(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "latent = tf.keras.layers.Dense(latent_dim, name = 'latent_vector') (x)\n",
        "\n",
        "# Build the Encoder\n",
        "encoder = tf.keras.Model(inputs, latent, name = 'encoder')\n",
        "# encoder.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(encoder, to_file = 'encoder_structure.png', \n",
        "                          show_shapes = True)\n",
        "\n",
        "# Build the Decoder\n",
        "latent_inputs = tf.keras.layers.Input(shape = (latent_dim, ), \n",
        "                                      name = 'decoder_input')\n",
        "\n",
        "x = tf.keras.layers.Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n",
        "x = tf.keras.layers.Reshape((shape[1], shape[2], shape[3]))(x)\n",
        "\n",
        "for filters in layer_filters[::-1]:\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters = filters, \n",
        "                                      kernel_size = kernel_size,\n",
        "                                      activation = 'relu', strides = 2, \n",
        "                                      padding = 'same')(x)\n",
        "\n",
        "outputs = tf.keras.layers.Conv2DTranspose(filters = 1, kernel_size = kernel_size,\n",
        "                                      activation = 'sigmoid', padding = 'same',\n",
        "                                      name = 'decoder_output')(x)\n",
        "\n",
        "decoder = tf.keras.Model(latent_inputs, outputs, name = 'decoder')\n",
        "#decoder.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(decoder, to_file = 'decoder.png', show_shapes = True)\n",
        "\n",
        "# Build the Autoencoder\n",
        "autoencoder = tf.keras.Model(inputs, decoder(encoder(inputs)), \n",
        "                             name = 'autoencoder')\n",
        "# autoencoder.summary()\n",
        "tf.keras.utils.plot_model(autoencoder, to_file = 'autoencoder_summary.png',\n",
        "                          show_shapes = True)\n",
        "\n",
        "autoencoder.compile(loss='mse', optimizer = 'adam')\n",
        "################################################################################\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8avXQgcXjms",
        "outputId": "3bef8b24-49b7-4b0d-e403-5beaa617b7d8"
      },
      "source": [
        "ae_hyb_time = 0\n",
        "cl_hyb_time = 0\n",
        "a_hyb_time = 0\n",
        "b_hyb_time = 0\n",
        "c_hyb_time = 0\n",
        "ind_time = 0\n",
        "\n",
        "start = time.time()\n",
        "cl_Hyb.fit(fx_train, \n",
        "          {\"Classifier2\" : fy_train, \"Generator2\": fx_train},\n",
        "          epochs = Epochs,\n",
        "          batch_size = batch_size,\n",
        "          callbacks=[tb_cb],)\n",
        "stop = time.time()\n",
        "cl_hyb_time = stop-start\n",
        "\n",
        "start = time.time()\n",
        "a_Hyb.fit(fx_train, \n",
        "          {\"Classifier3\" : fy_train, \"Generator3\": fx_train},\n",
        "          epochs = Epochs,\n",
        "          batch_size = batch_size,\n",
        "          callbacks=[tb_cb],)\n",
        "stop = time.time()\n",
        "a_hyb_time = stop-start\n",
        "\n",
        "start = time.time()\n",
        "b_Hyb.fit(fx_train, \n",
        "          {\"Classifier4\" : fy_train, \"Generator4\": fx_train},\n",
        "          epochs = Epochs,\n",
        "          batch_size = batch_size,\n",
        "          callbacks=[tb_cb],)\n",
        "stop = time.time()\n",
        "b_hyb_time = stop-start\n",
        "# reshape the datsets to accomodate the independent networks, renamed\n",
        "mxr = np.reshape(fx_train, [-1, 28, 28, 1])\n",
        "mxrt = np.reshape(fx_test, [-1, 28, 28, 1])\n",
        "\n",
        "start = time.time()\n",
        "cnn.fit(mxr, fy_train, epochs = Epochs, batch_size = batch_size,)\n",
        "autoencoder.fit(fxr, fx_train, epochs = Epochs, batch_size = batch_size)\n",
        "stop = time.time()\n",
        "ind_time = stop - start"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "570/938 [=================>............] - ETA: 2s - loss: 0.5493 - Classifier2_loss: 0.5493 - Generator2_loss: 0.1707 - Classifier2_accuracy: 0.8061 - Generator2_accuracy: 0.2471"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rTtvpczizuDY"
      },
      "source": [
        "\n",
        "print(\"CL Hybrid Training Time: \", cl_hyb_time)\n",
        "print(\"A Hybrid Training Time: \", a_hyb_time)\n",
        "print(\"B Hybrid Training Time: \", b_hyb_time)\n",
        "\n",
        "print(\"Independent Training Time: \", ind_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "frfMsvN2UVd4"
      },
      "source": [
        "\n",
        "ind_fpr = dict()\n",
        "ind_tpr = dict()\n",
        "chyb_fpr = dict()\n",
        "chyb_tpr = dict()\n",
        "ghyb_fpr = dict()\n",
        "ghyb_tpr = dict()\n",
        "\n",
        "c25_fpr = dict()\n",
        "c25_tpr = dict()\n",
        "c50_fpr = dict()\n",
        "c50_tpr = dict()\n",
        "c75_fpr = dict()\n",
        "c75_tpr = dict()\n",
        "\n",
        "\n",
        "# Create the merged test dataset and re evaluate \n",
        "x_test = np.append(mx_test, fx_test, axis = 0)\n",
        "y_test = np.append(my_test, fy_test, axis = 0)\n",
        "xtr = np.reshape(x_test, [-1, 28, 28, 1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cbtime=0\n",
        "gbtime=0\n",
        "atime=0\n",
        "btime=0\n",
        "ctime=0\n",
        "itime=0\n",
        "\n",
        "start = time.time()\n",
        "[CB_class, CB_gen] = cl_Hyb.predict(x_test) # Classifier Biased hybrid predictions\n",
        "stop = time.time()\n",
        "cbtime = stop-start\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "[C25_class, C25_gen] = a_Hyb.predict(x_test) # 25% class / 75% gen bias\n",
        "stop=time.time()\n",
        "atime=stop-start\n",
        "\n",
        "start=time.time()\n",
        "[C50_class, C50_gen] = b_Hyb.predict(x_test) # 50% class / 50% gen bias\n",
        "stop=time.time()\n",
        "btime=stop-start\n",
        "\n",
        "\n",
        "start=time.time()\n",
        "ind_class = cnn.predict(xtr) # Independent classifier predictions\n",
        "ind_gen = autoencoder.predict(x_test) # Independent Autoencoder generations\n",
        "stop=time.time()\n",
        "itime=stop-start\n",
        "\n",
        "sep_loss = np.empty(len(x_test))\n",
        "chyb_loss = np.empty(len(x_test))\n",
        "ghyb_loss = np.empty(len(x_test))\n",
        "c25_loss = np.empty(len(x_test))\n",
        "c50_loss = np.empty(len(x_test))\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(x_test)):\n",
        "  sep_loss[i] = img_rmse(x_test[i], np.squeeze(ind_gen[i]))\n",
        "  chyb_loss[i] = img_rmse(x_test[i], np.squeeze(CB_gen[i]))\n",
        "  c25_loss[i] = img_rmse(x_test[i], np.squeeze(C25_gen[i]))\n",
        "  c50_loss[i] = img_rmse(x_test[i], np.squeeze(C50_gen[i]))\n",
        "\n",
        "\n",
        "for i in range(15):\n",
        "  print('Classifier Biased Prediction: ',np.argmax(CB_class[i]),\n",
        "        '\\n Generator Biased Prediction: ',np.argmax(GB_class[i]),\n",
        "        '\\n 25% Classifier Biased Prediction: ',np.argmax(C25_class[i]),\n",
        "        '\\n 50% Classifier Biased Prediction: ',np.argmax(C50_class[i]),\n",
        "        '\\n 75% Classifier Biased Prediction: ',np.argmax(C75_class[i]),\n",
        "        '\\n Independent Network Prediction: ', np.argmax(ind_class[i]),\n",
        "        '\\n Actual Value: ', np.argmax(y_test[i]))\n",
        "  \n",
        "  print(' Independent Network RMSE: ', sep_loss[i],\n",
        "        '\\n Classifier Biased RMSE: ', chyb_loss[i],\n",
        "        '\\n Generator Biased RMSE: ', ghyb_loss[i],\n",
        "        '\\n 25% Classifier Biased RMSE: ', c25_loss[i],\n",
        "        '\\n 50% Classifier Biased RMSE: ', c50_loss[i],\n",
        "        '\\n 75% Classifier Biased RMSE: ', c75_loss[i])\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    ind_fpr[i], ind_tpr[i], _ = roc_curve(y_test[:,i], ind_class[:, i])\n",
        "    chyb_fpr[i], chyb_tpr[i], _ = roc_curve(y_test[:, i], CB_class[:, i])\n",
        "    ghyb_fpr[i], ghyb_tpr[i], _ = roc_curve(y_test[:, i], GB_class[:, i])\n",
        "    c25_fpr[i], c25_tpr[i], _ = roc_curve(y_test[:,i], C25_class[:, i])\n",
        "    c50_fpr[i], c50_tpr[i], _ = roc_curve(y_test[:, i], C50_class[:, i])\n",
        "    c75_fpr[i], c75_tpr[i], _ = roc_curve(y_test[:, i], C75_class[:, i])\n",
        "ind_fpr[\"micro\"], ind_tpr[\"micro\"], _ = roc_curve(y_test.ravel(), ind_class.ravel())\n",
        "chyb_fpr[\"micro\"], chyb_tpr[\"micro\"], _ = roc_curve(y_test.ravel(), CB_class.ravel())\n",
        "ghyb_fpr[\"micro\"], ghyb_tpr[\"micro\"], _ = roc_curve(y_test.ravel(), GB_class.ravel())\n",
        "c25_fpr[\"micro\"], c25_tpr[\"micro\"], _ = roc_curve(y_test.ravel(), C25_class.ravel())\n",
        "c50_fpr[\"micro\"], c50_tpr[\"micro\"], _ = roc_curve(y_test.ravel(), C50_class.ravel())\n",
        "c75_fpr[\"micro\"], c75_tpr[\"micro\"], _ = roc_curve(y_test.ravel(), C75_class.ravel())\n",
        "\n",
        "plt.figure()\n",
        "for i in range(10):\n",
        "  plt.plot(ind_fpr[i], ind_tpr[i],color = 'blue')\n",
        "  plt.plot(chyb_fpr[i], chyb_tpr[i], color = 'coral')\n",
        "  plt.plot(ghyb_fpr[i], ghyb_tpr[i], color = 'forestgreen')\n",
        "  plt.plot(c25_fpr[i], c25_tpr[i],color = 'black')\n",
        "  plt.plot(c50_fpr[i], c50_tpr[i], color = 'red')\n",
        "  plt.plot(c75_fpr[i], c75_tpr[i], color = 'orange')  \n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlim([-.05, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.legend()\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(ghyb_fpr[\"micro\"], ghyb_tpr[\"micro\"], color = 'forestgreen', label ='Gen. Bias')\n",
        "plt.plot(c25_fpr[\"micro\"], c25_tpr[\"micro\"], color = 'black', label = '25% Classifier Biased ')\n",
        "plt.plot(c50_fpr[\"micro\"], c50_tpr[\"micro\"], color = 'red', label = '50% Classifier Biased')\n",
        "plt.plot(c75_fpr[\"micro\"], c75_tpr[\"micro\"], color = 'orange', label ='75% Classifier Biased')\n",
        "plt.plot(ind_fpr[\"micro\"], ind_tpr[\"micro\"], color = 'blue', label = 'Independent')\n",
        "plt.legend()\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YS_JxPdzPX9p"
      },
      "source": [
        "print(np.average(sep_loss[:10000]))\n",
        "print(np.average(chyb_loss[:10000]))\n",
        "print(np.average(ghyb_loss[:10000]))\n",
        "print(np.average(c25_loss[:10000]))\n",
        "print(np.average(c50_loss[:10000]))\n",
        "print(np.average(c75_loss[:10000]))\n",
        "print()\n",
        "print(np.average(sep_loss[10001:]))\n",
        "print(np.average(chyb_loss[10001:]))\n",
        "print(np.average(ghyb_loss[10001:]))\n",
        "print(np.average(c25_loss[10001:]))\n",
        "print(np.average(c50_loss[10001:]))\n",
        "print(np.average(c75_loss[10001:]))\n",
        "\n",
        "\n",
        "print()\n",
        "print()\n",
        "print(\"AE Hybrid Evaluation Time: {}\", cbtime)\n",
        "print(\"CL Hybrid Evaluation Time: {}\", gbtime)\n",
        "print(\"A Hybrid Evaluation Time: {}\", atime)\n",
        "print(\"B Hybrid Evaluation Time: {}\", btime)\n",
        "print(\"C Hybrid Evaluation Time: {}\", ctime)\n",
        "print(\"Independent Evaluation Time: {}\", itime)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MwxZOBjPI8Mu"
      },
      "source": [
        "# Create Image and Label holding arrays for Watchdog\n",
        "aimg = []\n",
        "bimg = []\n",
        "cimg = []\n",
        "dimg = []\n",
        "eimg = []\n",
        "iimg = []\n",
        "alab = []\n",
        "blab = []\n",
        "clab = []\n",
        "dlab = []\n",
        "elab = []\n",
        "ilab = []\n",
        "\n",
        "# Create empty dictionaries for ROC curve FPR/TPR\n",
        "afpr = dict()\n",
        "bfpr = dict()\n",
        "cfpr = dict()\n",
        "dfpr = dict()\n",
        "efpr = dict()\n",
        "ifpr = dict()\n",
        "atpr = dict()\n",
        "btpr = dict()\n",
        "ctpr = dict()\n",
        "dtpr = dict()\n",
        "etpr = dict()\n",
        "itpr = dict()\n",
        "\n",
        "thresh = 4.5\n",
        "\n",
        "for i in range(len(x_test)):\n",
        "  real = x_test[i]\n",
        "  ap = np.squeeze(CB_gen[i])\n",
        "  bp = np.squeeze(GB_gen[i])\n",
        "  cp = np.squeeze(C25_gen[i])\n",
        "  dp = np.squeeze(C50_gen[i])\n",
        "  ep = np.squeeze(C75_gen[i])\n",
        "  ip = np.squeeze(ind_gen[i])\n",
        "\n",
        "  if(img_rmse(real, ap) < thresh):\n",
        "    aimg.append(x_test[i])\n",
        "    alab.append(y_test[i])\n",
        "\n",
        "  if(img_rmse(real, bp) < thresh):\n",
        "    bimg.append(x_test[i])\n",
        "    blab.append(y_test[i])\n",
        "\n",
        "  if(img_rmse(real, cp) < thresh):\n",
        "    cimg.append(x_test[i])\n",
        "    clab.append(y_test[i])\n",
        "\n",
        "  if(img_rmse(real, dp) < thresh):\n",
        "    dimg.append(x_test[i])\n",
        "    dlab.append(y_test[i])\n",
        "\n",
        "  if(img_rmse(real, ep) < thresh):\n",
        "    eimg.append(x_test[i])\n",
        "    elab.append(y_test[i])\n",
        "\n",
        "  if(img_rmse(real, ip) < thresh):\n",
        "    iimg.append(x_test[i])\n",
        "    ilab.append(y_test[i])\n",
        "\n",
        "\n",
        "aimg = np.array(aimg)\n",
        "bimg = np.array(bimg)\n",
        "cimg = np.array(cimg)\n",
        "dimg = np.array(dimg)\n",
        "eimg = np.array(eimg)\n",
        "iimg = np.array(iimg)\n",
        "\n",
        "alab = np.array(alab)\n",
        "blab = np.array(blab)\n",
        "clab = np.array(clab)\n",
        "dlab = np.array(dlab)\n",
        "elab = np.array(elab)\n",
        "ilab = np.array(ilab)\n",
        "\n",
        "iimg = np.reshape(iimg, [-1, 28, 28, 1])\n",
        "\n",
        "\n",
        "\n",
        "#[aprd, _] = cl_Hyb.predict(aimg)\n",
        "[bprd, _] = ae_Hyb.predict(bimg)\n",
        "[cprd, _] = a_Hyb.predict(cimg)\n",
        "[dprd, _] = b_Hyb.predict(dimg)\n",
        "[eprd, _] = c_Hyb.predict(eimg)\n",
        "iprd = cnn.predict(iimg)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3PclRIaxt75o"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "for i in range(10):\n",
        "    #afpr[i], atpr[i], _ = roc_curve(alab[:, i], aprd[:, i])\n",
        "    bfpr[i], btpr[i], _ = roc_curve(blab[:, i], bprd[:, i])\n",
        "    cfpr[i], ctpr[i], _ = roc_curve(clab[:, i], cprd[:, i])\n",
        "    dfpr[i], dtpr[i], _ = roc_curve(dlab[:, i], dprd[:, i])\n",
        "    efpr[i], etpr[i], _ = roc_curve(elab[:, i], eprd[:, i])\n",
        "    ifpr[i], itpr[i], _ = roc_curve(ilab[:, i], iprd[:, i])\n",
        "\n",
        "#afpr[\"micro\"], atpr[\"micro\"], _ = roc_curve(alab.ravel(), aprd.ravel())\n",
        "bfpr[\"micro\"], btpr[\"micro\"], _ = roc_curve(blab.ravel(), bprd.ravel())\n",
        "cfpr[\"micro\"], ctpr[\"micro\"], _ = roc_curve(clab.ravel(), cprd.ravel())\n",
        "dfpr[\"micro\"], dtpr[\"micro\"], _ = roc_curve(dlab.ravel(), dprd.ravel())\n",
        "efpr[\"micro\"], etpr[\"micro\"], _ = roc_curve(elab.ravel(), eprd.ravel())\n",
        "ifpr[\"micro\"], itpr[\"micro\"], _ = roc_curve(ilab.ravel(), iprd.ravel())\n",
        "\n",
        "plt.figure()\n",
        "for i in range(10):\n",
        "  #plt.plot(afpr[i], atpr[i],color = 'blue')\n",
        "  plt.plot(bfpr[i], btpr[i], color = 'forestgreen')\n",
        "  plt.plot(cfpr[i], ctpr[i], color = 'black')\n",
        "  plt.plot(dfpr[i], dtpr[i],color = 'red')\n",
        "  plt.plot(efpr[i], etpr[i], color = 'coral')\n",
        "  plt.plot(ifpr[i], itpr[i], color = 'blue')  \n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlim([-.05, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "#plt.plot(afpr[\"micro\"], atpr[\"micro\"], color = 'blue', label = 'Class. Bias')\n",
        "plt.plot(bfpr[\"micro\"], btpr[\"micro\"], color = 'forestgreen', label = 'Gen. Bias')\n",
        "plt.plot(cfpr[\"micro\"], ctpr[\"micro\"], color = 'black', label ='25% Class. Bias')\n",
        "plt.plot(dfpr[\"micro\"], dtpr[\"micro\"], color = 'red', label = '50% Class. Bias')\n",
        "plt.plot(efpr[\"micro\"], etpr[\"micro\"], color = 'coral', label = '75% Class. Bias')\n",
        "plt.plot(ifpr[\"micro\"], itpr[\"micro\"], color = 'blue', label ='Independent')\n",
        "plt.legend()\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "#plt.plot(afpr[\"micro\"], atpr[\"micro\"], color = 'blue', label = 'Class. Bias')\n",
        "plt.plot(bfpr[\"micro\"], btpr[\"micro\"], color = 'forestgreen', label = 'Gen. Bias')\n",
        "plt.plot(cfpr[\"micro\"], ctpr[\"micro\"], color = 'black', label ='25% Class. Bias')\n",
        "plt.plot(dfpr[\"micro\"], dtpr[\"micro\"], color = 'red', label = '50% Class. Bias')\n",
        "plt.plot(efpr[\"micro\"], etpr[\"micro\"], color = 'coral', label = '75% Class. Bias')\n",
        "plt.plot(ifpr[\"micro\"], itpr[\"micro\"], color = 'blue', label ='Independent')\n",
        "plt.legend()\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "plt.xlim([-0.01, 0.4])\n",
        "plt.ylim([0.55, 1.02])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}